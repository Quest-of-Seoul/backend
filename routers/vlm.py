"""
VLM Router - AR ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë¶„ì„ API
ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ VLM ë¶„ì„ â†’ ì¥ì†Œ ì‹ë³„ â†’ TTS ìƒì„±
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
from typing import Optional, List
import base64
import time
from io import BytesIO

# Services
from services.vlm import (
    analyze_place_image,
    extract_place_info_from_vlm_response,
    calculate_confidence_score
)
from services.embedding import (
    generate_image_embedding,
    hash_image
)
from services.db import (
    search_places_by_radius,
    get_place_by_name,
    save_vlm_log,
    get_cached_vlm_result,
    increment_place_view_count
)
# Pinecone vector store (ë²¡í„° ê²€ìƒ‰)
from services.pinecone_store import (
    search_similar_pinecone,
    upsert_pinecone
)
from services.ai import generate_docent_message
from services.tts import text_to_speech_url, text_to_speech
from services.storage import upload_audio_to_storage, compress_and_upload_image
import os

router = APIRouter()


# ============================================================
# Request/Response Models
# ============================================================

class VLMAnalyzeRequest(BaseModel):
    """ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­ (base64 ë°©ì‹ - Expo Go)"""
    user_id: str
    image: str  # base64 encoded
    latitude: Optional[float] = None
    longitude: Optional[float] = None
    language: str = "ko"
    prefer_url: bool = True  # True: URL ë°˜í™˜, False: base64 ë°˜í™˜
    enable_tts: bool = True
    use_cache: bool = True  # ìºì‹± ì‚¬ìš© ì—¬ë¶€


class SimilarImageRequest(BaseModel):
    """ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ìš”ì²­"""
    image: str  # base64 encoded
    limit: int = 3
    threshold: float = 0.7


# ============================================================
# Endpoints
# ============================================================

@router.post("/analyze")
async def analyze_image(request: VLMAnalyzeRequest):
    """
    AR ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë¶„ì„ (base64 ë°©ì‹)
    
    ì²˜ë¦¬ íë¦„:
    1. ì´ë¯¸ì§€ ìˆ˜ì‹  (base64)
    2. ì´ë¯¸ì§€ í•´ì‹œ ìƒì„± â†’ ìºì‹± ì²´í¬
    3. GPS ê¸°ë°˜ ì£¼ë³€ ì¥ì†Œ ê²€ìƒ‰
    4. ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± â†’ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    5. GPT-4V API í˜¸ì¶œ (ì´ë¯¸ì§€ ë¶„ì„)
    6. Geminië¡œ ìµœì¢… ì„¤ëª… ë³´ê°•
    7. TTS ìƒì„± (ì˜µì…˜)
    8. ë¡œê·¸ ì €ì¥
    """
    start_time = time.time()
    
    try:
        print(f"\n[VLM API] ğŸ¯ New analysis request from user: {request.user_id}")
        print(f"[VLM API] ğŸ“ GPS: ({request.latitude}, {request.longitude})")
        print(f"[VLM API] ğŸŒ Language: {request.language}, Provider: GPT-4V")
        
        # 1. Base64 ë””ì½”ë”©
        try:
            image_bytes = base64.b64decode(request.image)
            print(f"[VLM API] ğŸ“¸ Image decoded: {len(image_bytes)} bytes")
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Invalid base64 image: {str(e)}")
        
        # 2. ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
        image_hash = hash_image(image_bytes)
        print(f"[VLM API] ğŸ”‘ Image hash: {image_hash[:16]}...")
        
        # 3. ìºì‹± ì²´í¬ (ì„ íƒì )
        if request.use_cache:
            cached_result = get_cached_vlm_result(image_hash, max_age_hours=24)
            if cached_result:
                print("[VLM API] âš¡ Using cached result")
                return {
                    "cached": True,
                    "description": cached_result.get("final_description"),
                    "vlm_analysis": cached_result.get("vlm_response"),
                    "confidence_score": cached_result.get("confidence_score"),
                    "matched_place": cached_result.get("matched_place_id")
                }
        
        # 4. GPS ê¸°ë°˜ ì£¼ë³€ ì¥ì†Œ ê²€ìƒ‰
        nearby_places = []
        if request.latitude and request.longitude:
            nearby_places = search_places_by_radius(
                latitude=request.latitude,
                longitude=request.longitude,
                radius_km=1.0,
                limit_count=10
            )
            print(f"[VLM API] ğŸ“ Found {len(nearby_places)} nearby places")
        
        # 5. ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
        embedding = generate_image_embedding(image_bytes)
        if not embedding:
            print("[VLM API] âš ï¸ Embedding generation failed")
        
        # 6. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (Pinecone)
        similar_images = []
        best_similarity = 0.0
        if embedding:
            similar_images = search_similar_pinecone(
                embedding=embedding,
                match_threshold=0.6,
                match_count=3
            )
            if similar_images:
                best_similarity = similar_images[0].get("similarity", 0.0)
                print(f"[VLM API] ğŸ” Found {len(similar_images)} similar images (best: {best_similarity:.2f})")
        
        # 7. GPT-4V API í˜¸ì¶œ (ì´ë¯¸ì§€ ë¶„ì„)
        vlm_response = analyze_place_image(
            image_bytes=image_bytes,
            nearby_places=nearby_places,
            language=request.language
        )
        
        if not vlm_response:
            raise HTTPException(status_code=503, detail="VLM service unavailable")
        
        print(f"[VLM API] ğŸ¤– GPT-4V analysis complete: {len(vlm_response)} chars")
        
        # 8. VLM ì‘ë‹µì—ì„œ ì¥ì†Œ ì •ë³´ ì¶”ì¶œ
        place_info = extract_place_info_from_vlm_response(vlm_response)
        print(f"[VLM API] ğŸ“ Extracted place: {place_info.get('place_name', 'Unknown')}")
        
        # 9. ì¥ì†Œ ë§¤ì¹­ (DB ê²€ìƒ‰)
        matched_place = None
        matched_place_id = None
        
        if place_info.get("place_name"):
            # ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
            matched_place = get_place_by_name(place_info["place_name"], fuzzy=True)
            
            # ìœ ì‚¬ ì´ë¯¸ì§€ì—ì„œ ë§¤ì¹­
            if not matched_place and similar_images:
                matched_place = similar_images[0].get("place")
            
            if matched_place:
                matched_place_id = matched_place.get("id")
                print(f"[VLM API] âœ… Matched place: {matched_place.get('name')}")
                
                # ì¡°íšŒìˆ˜ ì¦ê°€
                increment_place_view_count(matched_place_id)
        
        # 10. GPS ê±°ë¦¬ ê³„ì‚°
        gps_distance = None
        if matched_place and request.latitude and request.longitude:
            for nearby in nearby_places:
                if nearby.get("id") == matched_place_id:
                    gps_distance = nearby.get("distance_km")
                    break
        
        # 11. ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
        confidence_score = calculate_confidence_score(
            vlm_info=place_info,
            vector_similarity=best_similarity if similar_images else None,
            gps_distance_km=gps_distance
        )
        print(f"[VLM API] ğŸ“Š Confidence score: {confidence_score}")
        
        # 12. Geminië¡œ ìµœì¢… ì„¤ëª… ë³´ê°•
        final_description = vlm_response
        
        if matched_place:
            # DB ë©”íƒ€ë°ì´í„°ì™€ VLM ë¶„ì„ ê²°í•©
            enhancement_prompt = f"""
VLM ë¶„ì„ ê²°ê³¼:
{vlm_response}

ì¥ì†Œ ì •ë³´:
- ì´ë¦„: {matched_place.get('name')}
- ì¹´í…Œê³ ë¦¬: {matched_place.get('category')}
- ì„¤ëª…: {matched_place.get('description')}
- ì£¼ì†Œ: {matched_place.get('address')}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ AR ë„ìŠ¨íŠ¸ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  í¥ë¯¸ë¡­ê²Œ 3-4ë¬¸ì¥ìœ¼ë¡œ ì´ ì¥ì†Œë¥¼ ì†Œê°œí•´ì£¼ì„¸ìš”.
"""
            try:
                final_description = generate_docent_message(
                    landmark=matched_place.get('name', 'ì´ ì¥ì†Œ'),
                    user_message=enhancement_prompt if request.language == "ko" else None,
                    language=request.language
                )
                print("[VLM API] âœ… Description enhanced by Gemini")
            except Exception as e:
                print(f"[VLM API] âš ï¸ Gemini enhancement failed: {e}")
        
        # 13. TTS ìƒì„± (ì˜µì…˜)
        audio_url = None
        audio_base64 = None
        
        if request.enable_tts:
            try:
                language_code = f"{request.language}-KR" if request.language == "ko" else "en-US"
                
                if request.prefer_url:
                    # URL ë°©ì‹ (Expo Go)
                    audio_url, audio_base64 = text_to_speech_url(
                        text=final_description,
                        language_code=language_code,
                        upload_to_storage=True
                    )
                    print(f"[VLM API] ğŸ”Š TTS generated (URL)")
                else:
                    # Base64 ë°©ì‹ (Standalone)
                    audio_base64 = text_to_speech(
                        text=final_description,
                        language_code=language_code
                    )
                    print(f"[VLM API] ğŸ”Š TTS generated (base64)")
            
            except Exception as tts_error:
                print(f"[VLM API] âš ï¸ TTS generation failed: {tts_error}")
        
        # 14. ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time_ms = int((time.time() - start_time) * 1000)
        print(f"[VLM API] â±ï¸ Processing time: {processing_time_ms}ms")
        
        # 15. ë¡œê·¸ ì €ì¥ (ì´ë¯¸ì§€ë¥¼ Storageì— ì—…ë¡œë“œ)
        try:
            # ì´ë¯¸ì§€ë¥¼ Supabase Storageì— ì—…ë¡œë“œ
            uploaded_image_url = compress_and_upload_image(
                image_bytes=image_bytes,
                max_size=1920,
                quality=85
            )
            
            save_vlm_log(
                user_id=request.user_id,
                image_url=uploaded_image_url,  # âœ… Storage URL
                latitude=request.latitude,
                longitude=request.longitude,
                vlm_provider="gpt4v",
                vlm_response=vlm_response,
                final_description=final_description,
                matched_place_id=matched_place_id,
                similar_places=[{"place_id": img.get("place", {}).get("id"), "similarity": img.get("similarity")} 
                               for img in similar_images],
                confidence_score=confidence_score,
                processing_time_ms=processing_time_ms,
                image_hash=image_hash
            )
        except Exception as log_error:
            print(f"[VLM API] âš ï¸ Failed to save log: {log_error}")
        
        # 16. ì‘ë‹µ ìƒì„±
        response_data = {
            "success": True,
            "description": final_description,
            "place": matched_place,
            "vlm_analysis": vlm_response,
            "similar_places": similar_images,
            "confidence_score": confidence_score,
            "processing_time_ms": processing_time_ms,
            "vlm_provider": "gpt4v"
        }
        
        # TTS ë°ì´í„° ì¶”ê°€
        if request.prefer_url and audio_url:
            response_data["audio_url"] = audio_url
        elif audio_base64:
            response_data["audio"] = audio_base64
        
        print(f"[VLM API] âœ… Analysis complete!\n")
        return response_data
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[VLM API] âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


@router.post("/analyze-multipart")
async def analyze_image_multipart(
    user_id: str = Form(...),
    image: UploadFile = File(...),
    latitude: Optional[float] = Form(None),
    longitude: Optional[float] = Form(None),
    language: str = Form("ko"),
    prefer_url: bool = Form(False),
    enable_tts: bool = Form(True)
):
    """
    AR ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë¶„ì„ (multipart/form-data ë°©ì‹ - Standalone)
    
    ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì—…ë¡œë“œì— ì í•©
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        
        # base64ë¡œ ë³€í™˜í•˜ì—¬ ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        
        request = VLMAnalyzeRequest(
            user_id=user_id,
            image=image_base64,
            latitude=latitude,
            longitude=longitude,
            language=language,
            prefer_url=prefer_url,
            enable_tts=enable_tts
        )
        
        return await analyze_image(request)
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Multipart upload failed: {str(e)}")


@router.post("/similar")
async def search_similar(request: SimilarImageRequest):
    """
    ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰)
    
    ì´¬ì˜í•œ ì‚¬ì§„ê³¼ ë¹„ìŠ·í•œ ì¥ì†Œ ì´ë¯¸ì§€ë¥¼ DBì—ì„œ ê²€ìƒ‰
    """
    try:
        print(f"[VLM API] ğŸ” Similar image search (limit: {request.limit})")
        
        # Base64 ë””ì½”ë”©
        image_bytes = base64.b64decode(request.image)
        
        # ì„ë² ë”© ìƒì„±
        embedding = generate_image_embedding(image_bytes)
        if not embedding:
            raise HTTPException(status_code=503, detail="Embedding service unavailable")
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰ (Pinecone)
        similar_images = search_similar_pinecone(
            embedding=embedding,
            match_threshold=request.threshold,
            match_count=request.limit
        )
        
        print(f"[VLM API] âœ… Found {len(similar_images)} similar images")
        
        return {
            "success": True,
            "count": len(similar_images),
            "similar_images": similar_images
        }
    
    except Exception as e:
        print(f"[VLM API] âŒ Error: {e}")
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")


@router.post("/embed")
async def create_embedding(
    place_id: str = Form(...),
    image: UploadFile = File(...)
):
    """
    ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ë° ì €ì¥ (ê´€ë¦¬ììš©)
    
    ì¥ì†Œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  Pineconeì— ì €ì¥
    """
    try:
        import uuid
        
        print(f"[VLM API] ğŸ“¤ Creating embedding for place: {place_id}")
        
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        
        # ì´ë¯¸ì§€ í•´ì‹œ
        img_hash = hash_image(image_bytes)
        
        # Supabase Storageì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
        image_url = compress_and_upload_image(
            image_bytes=image_bytes,
            max_size=1920,
            quality=85
        )
        
        if not image_url:
            raise HTTPException(status_code=500, detail="Image upload failed")
        
        print(f"[VLM API] âœ… Image uploaded: {image_url}")
        
        # ì„ë² ë”© ìƒì„±
        embedding = generate_image_embedding(image_bytes)
        if not embedding:
            raise HTTPException(status_code=503, detail="Embedding generation failed")
        
        # Pineconeì— ì €ì¥
        vector_id = str(uuid.uuid4())
        success = upsert_pinecone(
            vector_id=vector_id,
            embedding=embedding,
            metadata={
                "place_id": place_id,
                "image_url": image_url,
                "image_hash": img_hash,
                "source": "admin_upload",
                "filename": image.filename
            }
        )
        
        if not success:
            raise HTTPException(status_code=500, detail="Failed to save embedding")
        
        print(f"[VLM API] âœ… Embedding saved to Pinecone: {vector_id}")
        
        return {
            "success": True,
            "vector_id": vector_id,
            "place_id": place_id,
            "image_url": image_url,
            "embedding_dimension": len(embedding)
        }
    
    except Exception as e:
        print(f"[VLM API] âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Embedding creation failed: {str(e)}")


@router.get("/places/nearby")
async def get_nearby_places(
    latitude: float,
    longitude: float,
    radius_km: float = 1.0,
    limit: int = 10
):
    """
    GPS ê¸°ë°˜ ì£¼ë³€ ì¥ì†Œ ì¡°íšŒ
    """
    try:
        places = search_places_by_radius(
            latitude=latitude,
            longitude=longitude,
            radius_km=radius_km,
            limit_count=limit
        )
        
        return {
            "success": True,
            "count": len(places),
            "places": places
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Search failed: {str(e)}")


@router.get("/health")
async def health_check():
    """
    VLM ì„œë¹„ìŠ¤ ìƒíƒœ ì²´í¬
    """
    from services.vlm import OPENAI_AVAILABLE
    from services.embedding import CLIP_AVAILABLE
    
    # Pinecone ì—°ê²° í…ŒìŠ¤íŠ¸
    pinecone_available = False
    pinecone_stats = {}
    try:
        from services.pinecone_store import get_index_stats
        pinecone_stats = get_index_stats()
        pinecone_available = True
    except:
        pass
    
    return {
        "status": "healthy",
        "services": {
            "gpt4v": OPENAI_AVAILABLE,
            "clip": CLIP_AVAILABLE,
            "pinecone": pinecone_available
        },
        "pinecone_stats": pinecone_stats if pinecone_available else None
    }
