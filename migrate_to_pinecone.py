"""
Supabase pgvector ‚Üí Pinecone ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ïä§ÌÅ¨Î¶ΩÌä∏
Í∏∞Ï°¥ image_vectors ÌÖåÏù¥Î∏îÏùò Î™®Îì† Î≤°ÌÑ∞Î•º PineconeÏúºÎ°ú Ïù¥Ï†Ñ
"""

import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎìú
load_dotenv()

# ÏÑúÎπÑÏä§ import
from services.db import get_db
from services.pinecone_store import (
    upsert_batch_pinecone,
    get_index_stats,
    get_pinecone_index
)


def migrate_all_vectors(batch_size: int = 100, dry_run: bool = False):
    """
    Î™®Îì† Î≤°ÌÑ∞Î•º PineconeÏúºÎ°ú ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò
    
    Args:
        batch_size: Î∞∞Ïπò ÌÅ¨Í∏∞
        dry_run: TrueÎ©¥ Ïã§Ï†ú ÏóÖÎ°úÎìú ÏóÜÏù¥ ÌÖåÏä§Ìä∏Îßå
    """
    print("=" * 60)
    print("üöÄ Pinecone Migration - pgvector ‚Üí Pinecone")
    print("=" * 60)
    
    if dry_run:
        print("‚ö†Ô∏è  DRY RUN MODE - No actual upload will occur")
    
    try:
        # 1. SupabaseÏóêÏÑú Î™®Îì† Î≤°ÌÑ∞ Ï°∞Ìöå
        print("\nüìä Step 1: Fetching vectors from Supabase...")
        db = get_db()
        
        result = db.table("image_vectors").select("*").execute()
        
        if not result.data:
            print("‚ùå No vectors found in image_vectors table")
            print("\nüí° Tip: Run 'python seed_image_vectors.py --all' first")
            return
        
        vectors = result.data
        total = len(vectors)
        
        print(f"‚úÖ Found {total} vectors to migrate")
        
        # 2. Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù
        print("\nüîç Step 2: Validating data...")
        valid_vectors = []
        invalid_count = 0
        
        for vec in vectors:
            vector_id = vec.get('id')
            embedding = vec.get('embedding')
            place_id = vec.get('place_id')
            
            # ÌïÑÏàò ÌïÑÎìú Í≤ÄÏ¶ù
            if not vector_id or not embedding or not place_id:
                print(f"‚ö†Ô∏è  Skipping invalid vector: {vector_id}")
                invalid_count += 1
                continue
            
            # Î≤°ÌÑ∞ Ï∞®Ïõê Í≤ÄÏ¶ù
            if len(embedding) != 512:
                print(f"‚ö†Ô∏è  Skipping vector with wrong dimension: {vector_id} ({len(embedding)}D)")
                invalid_count += 1
                continue
            
            valid_vectors.append(vec)
        
        if invalid_count > 0:
            print(f"‚ö†Ô∏è  {invalid_count} invalid vectors skipped")
        
        print(f"‚úÖ {len(valid_vectors)} valid vectors ready")
        
        if len(valid_vectors) == 0:
            print("‚ùå No valid vectors to migrate")
            return
        
        # 3. Pinecone Ïó∞Í≤∞ ÌÖåÏä§Ìä∏
        print("\nüîå Step 3: Testing Pinecone connection...")
        
        try:
            index = get_pinecone_index()
            initial_stats = get_index_stats()
            print(f"‚úÖ Connected to Pinecone")
            print(f"   Current vectors: {initial_stats.get('total_vectors', 0)}")
            print(f"   Dimension: {initial_stats.get('dimension', 512)}")
        except Exception as e:
            print(f"‚ùå Failed to connect to Pinecone: {e}")
            print("\nüí° Tip: Run 'python setup_pinecone.py' first")
            return
        
        # 4. ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÌôïÏù∏
        if not dry_run:
            print(f"\n‚ö†Ô∏è  About to upload {len(valid_vectors)} vectors to Pinecone")
            response = input("Continue? (y/N): ").strip().lower()
            
            if response != 'y':
                print("‚ùå Migration cancelled")
                return
        
        # 5. Î∞∞Ïπò ÏóÖÎ°úÎìú
        print(f"\nüì§ Step 4: Uploading to Pinecone (batch size: {batch_size})...")
        
        # Pinecone ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
        pinecone_vectors = []
        for vec in valid_vectors:
            vector_tuple = (
                str(vec['id']),  # vector ID
                vec['embedding'],  # 512Ï∞®Ïõê Î≤°ÌÑ∞
                {
                    'place_id': vec['place_id'],
                    'image_url': vec.get('image_url', ''),
                    'image_hash': vec.get('image_hash', ''),
                    'source': vec.get('source', 'dataset'),
                    'created_at': vec.get('created_at', datetime.now().isoformat())
                }
            )
            pinecone_vectors.append(vector_tuple)
        
        if dry_run:
            print(f"‚úÖ DRY RUN: Would upload {len(pinecone_vectors)} vectors")
            print("\nSample vector:")
            if pinecone_vectors:
                sample = pinecone_vectors[0]
                print(f"  ID: {sample[0]}")
                print(f"  Embedding dim: {len(sample[1])}")
                print(f"  Metadata: {sample[2]}")
        else:
            # Ïã§Ï†ú ÏóÖÎ°úÎìú
            success_count = upsert_batch_pinecone(
                vectors=pinecone_vectors,
                batch_size=batch_size
            )
            
            print(f"\n‚úÖ Upload complete: {success_count}/{len(valid_vectors)}")
        
        # 6. Í≤∞Í≥º ÌôïÏù∏
        if not dry_run:
            print("\nüìä Step 5: Verifying migration...")
            
            import time
            time.sleep(2)  # Pinecone Ïù∏Îç±Ïã± ÎåÄÍ∏∞
            
            final_stats = get_index_stats()
            initial_count = initial_stats.get('total_vectors', 0)
            final_count = final_stats.get('total_vectors', 0)
            added = final_count - initial_count
            
            print(f"   Before: {initial_count} vectors")
            print(f"   After: {final_count} vectors")
            print(f"   Added: {added} vectors")
        
        # 7. ÏôÑÎ£å
        print("\n" + "=" * 60)
        print("üéâ Migration Complete!")
        print("=" * 60)
        
        if not dry_run:
            print("\n‚úÖ Next steps:")
            print("  1. Test the migration:")
            print("     python -c 'from services.pinecone_store import get_index_stats; print(get_index_stats())'")
            print("\n  2. Update your code to use Pinecone:")
            print("     - services/db.py ‚Üí services/pinecone_store.py")
            print("\n  3. Optional: Backup and drop image_vectors table")
            print("     (Keep places and vlm_logs tables!)")
        
    except Exception as e:
        print(f"\n‚ùå Migration failed: {e}")
        import traceback
        traceback.print_exc()


def verify_migration():
    """ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Í≤ÄÏ¶ù - ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ ÎπÑÍµê"""
    print("=" * 60)
    print("üîç Migration Verification")
    print("=" * 60)
    
    try:
        # SupabaseÏóêÏÑú ÏÉòÌîå Ï°∞Ìöå
        print("\n1Ô∏è‚É£ Checking Supabase...")
        db = get_db()
        supabase_result = db.table("image_vectors").select("id, place_id").limit(5).execute()
        
        if not supabase_result.data:
            print("‚ö†Ô∏è  No data in Supabase")
            return
        
        print(f"‚úÖ Found {len(supabase_result.data)} sample vectors in Supabase")
        
        # PineconeÏóêÏÑú ÌôïÏù∏
        print("\n2Ô∏è‚É£ Checking Pinecone...")
        from services.pinecone_store import fetch_vector_by_id
        
        matched = 0
        missing = []
        
        for vec in supabase_result.data:
            vec_id = str(vec['id'])
            pinecone_vec = fetch_vector_by_id(vec_id)
            
            if pinecone_vec:
                matched += 1
                print(f"‚úÖ {vec_id[:8]}... - Found in Pinecone")
            else:
                missing.append(vec_id)
                print(f"‚ùå {vec_id[:8]}... - Missing in Pinecone")
        
        # Í≤∞Í≥º
        print("\n" + "=" * 60)
        print(f"üìä Verification Result:")
        print(f"   Matched: {matched}/{len(supabase_result.data)}")
        
        if missing:
            print(f"   Missing: {len(missing)}")
            print(f"   IDs: {missing}")
        else:
            print("   ‚úÖ All sample vectors found in Pinecone!")
        print("=" * 60)
    
    except Exception as e:
        print(f"‚ùå Verification failed: {e}")


def compare_search_results():
    """Í≤ÄÏÉâ Í≤∞Í≥º ÎπÑÍµê - pgvector vs Pinecone"""
    print("=" * 60)
    print("üîç Search Comparison - pgvector vs Pinecone")
    print("=" * 60)
    
    try:
        # ÌÖåÏä§Ìä∏Ïö© Î≤°ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
        db = get_db()
        result = db.table("image_vectors").select("embedding").limit(1).execute()
        
        if not result.data or not result.data[0].get('embedding'):
            print("‚ùå No test vector found")
            return
        
        test_embedding = result.data[0]['embedding']
        print(f"‚úÖ Using test vector (dim: {len(test_embedding)})")
        
        # pgvector Í≤ÄÏÉâ
        print("\n1Ô∏è‚É£ pgvector search...")
        from services.db import search_similar_images as search_pgvector
        
        pgvector_results = search_pgvector(
            embedding=test_embedding,
            match_threshold=0.7,
            match_count=5
        )
        
        print(f"‚úÖ pgvector found: {len(pgvector_results)} results")
        
        # Pinecone Í≤ÄÏÉâ
        print("\n2Ô∏è‚É£ Pinecone search...")
        from services.pinecone_store import search_similar_pinecone
        
        pinecone_results = search_similar_pinecone(
            embedding=test_embedding,
            match_threshold=0.7,
            match_count=5
        )
        
        print(f"‚úÖ Pinecone found: {len(pinecone_results)} results")
        
        # ÎπÑÍµê
        print("\n" + "=" * 60)
        print("üìä Comparison:")
        print(f"   pgvector: {len(pgvector_results)} results")
        print(f"   Pinecone: {len(pinecone_results)} results")
        
        if len(pgvector_results) > 0 and len(pinecone_results) > 0:
            print("\n   Top result comparison:")
            print(f"   pgvector similarity: {pgvector_results[0].get('similarity', 0):.4f}")
            print(f"   Pinecone similarity: {pinecone_results[0].get('similarity', 0):.4f}")
        
        print("=" * 60)
    
    except Exception as e:
        print(f"‚ùå Comparison failed: {e}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Migrate vectors from pgvector to Pinecone")
    parser.add_argument("--dry-run", action="store_true", help="Test without uploading")
    parser.add_argument("--batch-size", type=int, default=100, help="Batch size for upload")
    parser.add_argument("--verify", action="store_true", help="Verify migration")
    parser.add_argument("--compare", action="store_true", help="Compare search results")
    
    args = parser.parse_args()
    
    if args.verify:
        verify_migration()
    elif args.compare:
        compare_search_results()
    else:
        migrate_all_vectors(
            batch_size=args.batch_size,
            dry_run=args.dry_run
        )
