"""
ë¹„ë™ê¸° ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬ ì„œë¹„ìŠ¤
ëŒ€ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œ ì„±ëŠ¥ ìµœì í™”
"""

import asyncio
import aiohttp
from typing import List, Dict, Optional, Tuple
from io import BytesIO
import time

from services.embedding import generate_embeddings_batch, hash_image
from services.pinecone_store import upsert_batch_pinecone


async def download_image_async(url: str, session: aiohttp.ClientSession) -> Optional[bytes]:
    """
    ë¹„ë™ê¸° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    
    Args:
        url: ì´ë¯¸ì§€ URL
        session: aiohttp ì„¸ì…˜
    
    Returns:
        ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë˜ëŠ” None
    """
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
            if response.status == 200:
                return await response.read()
            else:
                print(f"âš ï¸  Failed to download {url}: Status {response.status}")
                return None
    
    except Exception as e:
        print(f"âš ï¸  Download error for {url}: {e}")
        return None


async def download_images_batch(
    urls: List[str],
    max_concurrent: int = 10
) -> List[Optional[bytes]]:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë³‘ë ¬ë¡œ ë‹¤ìš´ë¡œë“œ
    
    Args:
        urls: ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸
        max_concurrent: ìµœëŒ€ ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜
    
    Returns:
        ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    connector = aiohttp.TCPConnector(limit=max_concurrent)
    
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = [download_image_async(url, session) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Exceptionì„ Noneìœ¼ë¡œ ë³€í™˜
        images = []
        for result in results:
            if isinstance(result, Exception):
                images.append(None)
            else:
                images.append(result)
        
        return images


def process_places_batch(
    places: List[Dict],
    batch_size: int = 10,
    max_concurrent_downloads: int = 5
) -> Tuple[int, int]:
    """
    ì—¬ëŸ¬ ì¥ì†Œì˜ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ Pineconeì— ì €ì¥
    
    Args:
        places: ì¥ì†Œ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (id, name, image_url í¬í•¨)
        batch_size: ì„ë² ë”© ë°°ì¹˜ í¬ê¸°
        max_concurrent_downloads: ìµœëŒ€ ë™ì‹œ ë‹¤ìš´ë¡œë“œ
    
    Returns:
        (ì„±ê³µ ìˆ˜, ì‹¤íŒ¨ ìˆ˜)
    """
    print(f"\nğŸš€ Batch Embedding Process")
    print(f"Total places: {len(places)}")
    print(f"Batch size: {batch_size}")
    print(f"Max concurrent downloads: {max_concurrent_downloads}")
    
    success_count = 0
    fail_count = 0
    
    start_time = time.time()
    
    for batch_idx in range(0, len(places), batch_size):
        batch = places[batch_idx:batch_idx + batch_size]
        batch_num = batch_idx // batch_size + 1
        total_batches = (len(places) + batch_size - 1) // batch_size
        
        print(f"\n[Batch {batch_num}/{total_batches}]")
        
        # 1. ë¹„ë™ê¸° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        urls = [p.get("image_url") for p in batch if p.get("image_url")]
        
        if not urls:
            print("âš ï¸  No valid URLs in batch")
            fail_count += len(batch)
            continue
        
        print(f"ğŸ“¥ Downloading {len(urls)} images...")
        images = asyncio.run(download_images_batch(urls, max_concurrent_downloads))
        
        downloaded_count = sum(1 for img in images if img is not None)
        print(f"âœ… Downloaded: {downloaded_count}/{len(urls)}")
        
        # 2. CLIP ë°°ì¹˜ ì„ë² ë”© ìƒì„±
        print(f"ğŸ§  Generating embeddings...")
        
        valid_images = [img for img in images if img is not None]
        
        if not valid_images:
            print("âŒ No valid images to process")
            fail_count += len(batch)
            continue
        
        embeddings = generate_embeddings_batch(valid_images, batch_size=batch_size)
        
        # 3. Pinecone ì—…ë¡œë“œ ì¤€ë¹„
        pinecone_vectors = []
        
        for place, image_bytes, embedding in zip(batch, images, embeddings):
            if image_bytes is None or embedding is None:
                fail_count += 1
                continue
            
            import uuid
            vector_id = str(uuid.uuid4())
            img_hash = hash_image(image_bytes)
            
            pinecone_vectors.append((
                vector_id,
                embedding,
                {
                    "place_id": place["id"],
                    "place_name": place.get("name", ""),
                    "image_url": place.get("image_url", ""),
                    "image_hash": img_hash,
                    "category": place.get("category", ""),
                    "source": place.get("source", "tour_api")
                }
            ))
        
        # 4. Pinecone ì—…ë¡œë“œ
        if pinecone_vectors:
            print(f"ğŸ’¾ Uploading to Pinecone...")
            uploaded = upsert_batch_pinecone(pinecone_vectors, batch_size=100)
            success_count += uploaded
            print(f"âœ… Uploaded: {uploaded}")
        
        # API rate limit ë°©ì§€
        time.sleep(0.5)
    
    elapsed_time = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ‰ Batch Process Complete")
    print("=" * 60)
    print(f"âœ… Success: {success_count}/{len(places)}")
    print(f"âŒ Failed: {fail_count}/{len(places)}")
    print(f"â±ï¸  Time: {elapsed_time:.1f}s")
    print(f"ğŸ“Š Speed: {len(places)/elapsed_time:.1f} images/sec")
    print("=" * 60)
    
    return success_count, fail_count


def process_tour_api_places():
    """
    TourAPIë¡œ ìˆ˜ì§‘í•œ ì¥ì†Œë“¤ì˜ ì„ë² ë”© ìƒì„±
    """
    from services.db import get_db
    
    print("=" * 60)
    print("ğŸ”„ Processing TourAPI Places")
    print("=" * 60)
    
    try:
        db = get_db()
        
        # TourAPI ì¥ì†Œë§Œ ì¡°íšŒ (ì•„ì§ ì„ë² ë”© ì•ˆëœ ê²ƒ)
        result = db.table("places") \
            .select("id, name, category, image_url, source") \
            .eq("source", "tour_api") \
            .eq("is_active", True) \
            .execute()
        
        places = result.data
        
        if not places:
            print("âš ï¸  No TourAPI places found")
            print("Run: python scripts/fetch_tour_api.py --all")
            return
        
        print(f"ğŸ“Š Found {len(places)} TourAPI places")
        
        # ë°°ì¹˜ ì²˜ë¦¬
        process_places_batch(
            places=places,
            batch_size=10,
            max_concurrent_downloads=5
        )
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¹„ë™ê¸° ë°°ì¹˜ ì„ë² ë”© ì²˜ë¦¬")
    parser.add_argument("--tour-api", action="store_true", help="TourAPI ì¥ì†Œë§Œ ì²˜ë¦¬")
    
    args = parser.parse_args()
    
    if args.tour_api:
        process_tour_api_places()
    else:
        print("Usage:")
        print("  python -m services.batch_embedding --tour-api")
